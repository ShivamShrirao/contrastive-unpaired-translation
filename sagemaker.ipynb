{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95c0a6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import os\n",
    "import wandb\n",
    "from sagemaker.pytorch import PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d61bc4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't call 'get_role' to get Role ARN from role name Shivam to get Role path.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    sagemaker_session = sagemaker.Session()\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_permissions')['Role']['Arn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbbed229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://ai-sagemaker-weights/seat-gen-unpaired-2022-08-26-18-53-05\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "bucket = \"ai-sagemaker-weights\"\n",
    "base_job_name = \"seat-gen-unpaired\"\n",
    "checkpoint_suffix = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "checkpoint_s3_path = f\"s3://{bucket}/{base_job_name}-{checkpoint_suffix}\"\n",
    "print(checkpoint_s3_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0229bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = os.getcwd()\n",
    "wandb.sagemaker_auth(path=source_dir)\n",
    "\n",
    "estimator = PyTorch(entry_point='sage_train.sh',\n",
    "                    source_dir=source_dir,\n",
    "                    role=role,\n",
    "                    py_version='py38',\n",
    "                    framework_version='1.11.0',\n",
    "                    base_job_name=base_job_name,\n",
    "                    checkpoint_s3_uri=checkpoint_s3_path,\n",
    "#                     input_mode='FastFile',\n",
    "                    instance_count=1,\n",
    "                    instance_type='ml.g5.xlarge',\n",
    "                    use_spot_instances=True,  # Use a spot instance\n",
    "                    max_run=2*24*60*60,  # Max training time\n",
    "                    max_wait=2*24*60*60,  # Max training time + spot waiting time seconds\n",
    "                    hyperparameters={\n",
    "                        \"encoder\": \"seresnet18\",\n",
    "                        \"n_epochs\": 100,\n",
    "                        \"n_epochs_decay\": 100,\n",
    "                        \"batch_size\": 16,\n",
    "                        \"lr\": 0.0002,\n",
    "                        \"n_layers_D\": 3,\n",
    "                        \"project\": \"new_cut\",\n",
    "                        \"use_wandb\": True,\n",
    "                        \"name\": \"no_windows/\",\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3bc552",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-26 13:23:22 Starting - Starting the training job...\n",
      "2022-08-26 13:23:44 Starting - Preparing the instances for trainingProfilerReport-1661520200: InProgress\n",
      "......\n",
      "2022-08-26 13:25:05 Downloading - Downloading input data...............................................................................................\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2022-08-26 13:43:23,707 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2022-08-26 13:43:23,726 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2022-08-26 13:43:23,732 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2022-08-26 13:43:24,852 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g5.xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch_size\": 8,\n",
      "        \"encoder\": \"legacy_seresnext26_32x4d\",\n",
      "        \"lr\": 0.0002,\n",
      "        \"n_epochs\": 100,\n",
      "        \"n_epochs_decay\": 100,\n",
      "        \"n_layers_D\": 4,\n",
      "        \"name\": \"no_windows/\",\n",
      "        \"project\": \"new_cut\",\n",
      "        \"use_wandb\": true\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g5.xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"job_name\": \"seat-gen-unpaired-2022-08-26-13-23-06-678\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-257240243617/seat-gen-unpaired-2022-08-26-13-23-06-678/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"sage_train.sh\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g5.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g5.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"sage_train.sh\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch_size\":8,\"encoder\":\"legacy_seresnext26_32x4d\",\"lr\":0.0002,\"n_epochs\":100,\"n_epochs_decay\":100,\"n_layers_D\":4,\"name\":\"no_windows/\",\"project\":\"new_cut\",\"use_wandb\":true}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=sage_train.sh\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.g5.xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=sage_train.sh\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-257240243617/seat-gen-unpaired-2022-08-26-13-23-06-678/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g5.xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch_size\":8,\"encoder\":\"legacy_seresnext26_32x4d\",\"lr\":0.0002,\"n_epochs\":100,\"n_epochs_decay\":100,\"n_layers_D\":4,\"name\":\"no_windows/\",\"project\":\"new_cut\",\"use_wandb\":true},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"job_name\":\"seat-gen-unpaired-2022-08-26-13-23-06-678\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-257240243617/seat-gen-unpaired-2022-08-26-13-23-06-678/source/sourcedir.tar.gz\",\"module_name\":\"sage_train.sh\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"sage_train.sh\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch_size\",\"8\",\"--encoder\",\"legacy_seresnext26_32x4d\",\"--lr\",\"0.0002\",\"--n_epochs\",\"100\",\"--n_epochs_decay\",\"100\",\"--n_layers_D\",\"4\",\"--name\",\"no_windows/\",\"--project\",\"new_cut\",\"--use_wandb\",\"True\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH_SIZE=8\u001b[0m\n",
      "\u001b[34mSM_HP_ENCODER=legacy_seresnext26_32x4d\u001b[0m\n",
      "\u001b[34mSM_HP_LR=0.0002\u001b[0m\n",
      "\u001b[34mSM_HP_N_EPOCHS=100\u001b[0m\n",
      "\u001b[34mSM_HP_N_EPOCHS_DECAY=100\u001b[0m\n",
      "\u001b[34mSM_HP_N_LAYERS_D=4\u001b[0m\n",
      "\u001b[34mSM_HP_NAME=no_windows/\u001b[0m\n",
      "\u001b[34mSM_HP_PROJECT=new_cut\u001b[0m\n",
      "\u001b[34mSM_HP_USE_WANDB=true\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/lib/python3.8/site-packages/smdistributed/dataparallel/lib:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.16b20220819-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/bin/sh -c \"./sage_train.sh --batch_size 8 --encoder legacy_seresnext26_32x4d --lr 0.0002 --n_epochs 100 --n_epochs_decay 100 --n_layers_D 4 --name no_windows/ --project new_cut --use_wandb True\"\u001b[0m\n",
      "\u001b[34mCollecting wandb\u001b[0m\n",
      "\u001b[34mDownloading wandb-0.13.2-py2.py3-none-any.whl (1.8 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.8/1.8 MB 46.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from -r code/requirements.txt (line 2)) (4.64.0)\u001b[0m\n",
      "\u001b[34mCollecting timm\u001b[0m\n",
      "\u001b[34mDownloading timm-0.6.7-py3-none-any.whl (509 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 510.0/510.0 kB 38.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting albumentations\u001b[0m\n",
      "\u001b[34mDownloading albumentations-1.2.1-py3-none-any.whl (116 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 116.7/116.7 kB 6.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.8/site-packages (from wandb->-r code/requirements.txt (line 1)) (5.9.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: PyYAML in /opt/conda/lib/python3.8/site-packages (from wandb->-r code/requirements.txt (line 1)) (5.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from wandb->-r code/requirements.txt (line 1)) (65.0.2)\u001b[0m\n",
      "\u001b[34mCollecting GitPython>=1.0.0\u001b[0m\n",
      "\u001b[34mDownloading GitPython-3.1.27-py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 181.2/181.2 kB 28.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting docker-pycreds>=0.4.0\u001b[0m\n",
      "\u001b[34mDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from wandb->-r code/requirements.txt (line 1)) (2.28.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: Click!=8.0.0,>=7.0 in /opt/conda/lib/python3.8/site-packages (from wandb->-r code/requirements.txt (line 1)) (8.1.3)\u001b[0m\n",
      "\u001b[34mCollecting promise<3,>=2.0\u001b[0m\n",
      "\u001b[34mDownloading promise-2.3.tar.gz (19 kB)\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.8/site-packages (from wandb->-r code/requirements.txt (line 1)) (1.16.0)\u001b[0m\n",
      "\u001b[34mCollecting pathtools\u001b[0m\n",
      "\u001b[34mDownloading pathtools-0.1.2.tar.gz (11 kB)\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf<4.0dev,>=3.12.0 in /opt/conda/lib/python3.8/site-packages (from wandb->-r code/requirements.txt (line 1)) (3.19.4)\u001b[0m\n",
      "\u001b[34mCollecting shortuuid>=0.5.0\u001b[0m\n",
      "\u001b[34mDownloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\u001b[0m\n",
      "\u001b[34mCollecting sentry-sdk>=1.0.0\u001b[0m\n",
      "\u001b[34mDownloading sentry_sdk-1.9.5-py2.py3-none-any.whl (157 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 157.6/157.6 kB 30.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting setproctitle\u001b[0m\n",
      "\u001b[34mDownloading setproctitle-1.3.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch>=1.4 in /opt/conda/lib/python3.8/site-packages (from timm->-r code/requirements.txt (line 3)) (1.11.0+cu113)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torchvision in /opt/conda/lib/python3.8/site-packages (from timm->-r code/requirements.txt (line 3)) (0.12.0+cu113)\u001b[0m\n",
      "\u001b[34mCollecting scikit-image>=0.16.1\u001b[0m\n",
      "\u001b[34mDownloading scikit_image-0.19.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 14.0/14.0 MB 96.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy in /opt/conda/lib/python3.8/site-packages (from albumentations->-r code/requirements.txt (line 4)) (1.9.0)\u001b[0m\n",
      "\u001b[34mCollecting qudida>=0.0.4\u001b[0m\n",
      "\u001b[34mDownloading qudida-0.0.4-py3-none-any.whl (3.5 kB)\u001b[0m\n",
      "\u001b[34mCollecting opencv-python-headless>=4.1.1\u001b[0m\n",
      "\u001b[34mDownloading opencv_python_headless-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (48.3 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 48.3/48.3 MB 49.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.11.1 in /opt/conda/lib/python3.8/site-packages (from albumentations->-r code/requirements.txt (line 4)) (1.22.2)\u001b[0m\n",
      "\u001b[34mCollecting gitdb<5,>=4.0.1\u001b[0m\n",
      "\u001b[34mDownloading gitdb-4.0.9-py3-none-any.whl (63 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 63.1/63.1 kB 13.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from qudida>=0.0.4->albumentations->-r code/requirements.txt (line 4)) (4.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scikit-learn>=0.19.1 in /opt/conda/lib/python3.8/site-packages (from qudida>=0.0.4->albumentations->-r code/requirements.txt (line 4)) (1.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb->-r code/requirements.txt (line 1)) (1.26.11)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb->-r code/requirements.txt (line 1)) (2.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb->-r code/requirements.txt (line 1)) (3.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb->-r code/requirements.txt (line 1)) (2022.6.15)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /opt/conda/lib/python3.8/site-packages (from scikit-image>=0.16.1->albumentations->-r code/requirements.txt (line 4)) (9.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx>=2.2 in /opt/conda/lib/python3.8/site-packages (from scikit-image>=0.16.1->albumentations->-r code/requirements.txt (line 4)) (2.8.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: imageio>=2.4.1 in /opt/conda/lib/python3.8/site-packages (from scikit-image>=0.16.1->albumentations->-r code/requirements.txt (line 4)) (2.21.1)\u001b[0m\n",
      "\u001b[34mCollecting PyWavelets>=1.1.1\u001b[0m\n",
      "\u001b[34mDownloading PyWavelets-1.3.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.9 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.9/6.9 MB 102.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from scikit-image>=0.16.1->albumentations->-r code/requirements.txt (line 4)) (21.3)\u001b[0m\n",
      "\u001b[34mCollecting tifffile>=2019.7.26\u001b[0m\n",
      "\u001b[34mDownloading tifffile-2022.8.12-py3-none-any.whl (208 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 208.5/208.5 kB 16.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting smmap<6,>=3.0.1\u001b[0m\n",
      "\u001b[34mDownloading smmap-5.0.0-py3-none-any.whl (24 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->scikit-image>=0.16.1->albumentations->-r code/requirements.txt (line 4)) (3.0.9)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations->-r code/requirements.txt (line 4)) (3.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations->-r code/requirements.txt (line 4)) (1.1.0)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: promise, pathtools\u001b[0m\n",
      "\u001b[34mBuilding wheel for promise (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for promise (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for promise: filename=promise-2.3-py3-none-any.whl size=21486 sha256=a3d778a14ee8b9f010950324a311c339f54a57c5d3bf169282a5eb880bc4238f\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/54/aa/01/724885182f93150035a2a91bce34a12877e8067a97baaf5dc8\u001b[0m\n",
      "\u001b[34mBuilding wheel for pathtools (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for pathtools (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8792 sha256=8c54441f3be4a2579cac2c80027d4a6ad99e4a141ea550866ff7fe997813f919\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/4c/8e/7e/72fbc243e1aeecae64a96875432e70d4e92f3d2d18123be004\u001b[0m\n",
      "\u001b[34mSuccessfully built promise pathtools\u001b[0m\n",
      "\u001b[34mInstalling collected packages: pathtools, tifffile, smmap, shortuuid, setproctitle, sentry-sdk, PyWavelets, promise, opencv-python-headless, docker-pycreds, scikit-image, gitdb, timm, qudida, GitPython, wandb, albumentations\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2022-08-26 13:43:49 Training - Training image download completed. Training in progress.\u001b[34mSuccessfully installed GitPython-3.1.27 PyWavelets-1.3.0 albumentations-1.2.1 docker-pycreds-0.4.0 gitdb-4.0.9 opencv-python-headless-4.6.0.66 pathtools-0.1.2 promise-2.3 qudida-0.0.4 scikit-image-0.19.3 sentry-sdk-1.9.5 setproctitle-1.3.2 shortuuid-1.0.9 smmap-5.0.0 tifffile-2022.8.12 timm-0.6.7 wandb-0.13.2\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\u001b[0m\n",
      "\u001b[34m----------------- Options ---------------\n",
      "                 CUT_mode: CUT                           \n",
      "              DiffAugment: False                         \n",
      "       DiffAugment_policy: color,translation,cutout      \n",
      "               batch_size: 8                             #011[default: 1]\n",
      "                    beta1: 0.5                           \n",
      "                    beta2: 0.999                         \n",
      "          checkpoints_dir: /opt/ml/checkpoints/          \n",
      "                 dataroot: /opt/ml/input/data/train      \n",
      "                  encoder: legacy_seresnext26_32x4d      #011[default: seresnet18]\n",
      "        flip_equivariance: False                         \n",
      "                 gan_mode: lsgan                         \n",
      "         img_log_interval: 500                           \n",
      "               init_epoch: 1                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: xavier                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: True                          #011[default: None]\n",
      "               lambda_GAN: 1.0                           \n",
      "               lambda_NCE: 1.0                           \n",
      "             log_interval: 20                            \n",
      "                       lr: 0.0002                        \n",
      "                 n_epochs: 100                           #011[default: 200]\n",
      "           n_epochs_decay: 100                           #011[default: 200]\n",
      "               n_layers_D: 4                             #011[default: 3]\n",
      "                     name: no_windows/                   #011[default: new_cut]\n",
      "                    nce_T: 0.07                          \n",
      "                  nce_idt: True                          \u001b[0m\n",
      "\u001b[34mnce_includes_all_negatives_from_minibatch: False                         \n",
      "               nce_layers: 0,4,8,12,16                   \n",
      "                      ndf: 64                            \n",
      "                     netF: mlp_sample                    \n",
      "                  netF_nc: 256                           \n",
      "                      ngf: 32                            \n",
      "                   no_amp: False                         \n",
      "             no_antialias: False                         \n",
      "          no_antialias_up: False                         \n",
      "               no_dropout: True                          \n",
      "                    normD: instance                      \n",
      "                    normG: instance                      \n",
      "              num_patches: 256                           \n",
      "                output_nc: 3                             \n",
      "                    phase: train                         \n",
      "                pool_size: 50                            \n",
      "                  project: new_cut                       #011[default: nerf_refine]\n",
      "                     seed: 1337                          \n",
      "                  sync_bn: False                         \n",
      "                use_wandb: True                          \n",
      "                       wd: 0.0005                        \n",
      "                  workers: 8                             \u001b[0m\n",
      "\u001b[34m----------------- End -------------------\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\u001b[0m\n",
      "\u001b[34mwandb: Currently logged in as: shivamshrirao. Use `wandb login --relogin` to force relogin\u001b[0m\n",
      "\u001b[34mwandb: Tracking run with wandb version 0.13.2\u001b[0m\n",
      "\u001b[34mwandb: Run data is saved locally in /opt/ml/code/wandb/run-20220826_134342-seat-gen-unpaired-2022-08-26-13-23-06-678-algo-1\u001b[0m\n",
      "\u001b[34mwandb: Run `wandb offline` to turn off syncing.\u001b[0m\n",
      "\u001b[34mwandb: Syncing run seat-gen-unpaired-2022-08-26-13-23-06-678-algo-1\u001b[0m\n",
      "\u001b[34mwandb: ⭐️ View project at https://wandb.ai/shivamshrirao/new_cut\u001b[0m\n",
      "\u001b[34mwandb: 🚀 View run at https://wandb.ai/shivamshrirao/new_cut/runs/seat-gen-unpaired-2022-08-26-13-23-06-678-algo-1\u001b[0m\n",
      "\u001b[34mDownloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/seresnext26_32x4d-65ebdb501.pth\" to /root/.cache/torch/hub/checkpoints/seresnext26_32x4d-65ebdb501.pth\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.651 algo-1:73 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/smdebug-1.0.16b20220819-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/smdebug-1.0.16b20220819-py3.8.egg/smdebug/profiler/system_metrics_reader.py:63: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.800 algo-1:73 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.801 algo-1:73 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.802 algo-1:73 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.803 algo-1:73 INFO hook.py:254] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.806 algo-1:73 INFO hook.py:560] name:layer0.conv1.weight count_params:9408\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.806 algo-1:73 INFO hook.py:560] name:layer0.bn1.weight count_params:64\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.807 algo-1:73 INFO hook.py:560] name:layer0.bn1.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.807 algo-1:73 INFO hook.py:560] name:layer1.0.conv1.weight count_params:8192\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.807 algo-1:73 INFO hook.py:560] name:layer1.0.bn1.weight count_params:128\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.807 algo-1:73 INFO hook.py:560] name:layer1.0.bn1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.807 algo-1:73 INFO hook.py:560] name:layer1.0.conv2.weight count_params:4608\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.807 algo-1:73 INFO hook.py:560] name:layer1.0.bn2.weight count_params:128\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.808 algo-1:73 INFO hook.py:560] name:layer1.0.bn2.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.808 algo-1:73 INFO hook.py:560] name:layer1.0.conv3.weight count_params:32768\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.808 algo-1:73 INFO hook.py:560] name:layer1.0.bn3.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.808 algo-1:73 INFO hook.py:560] name:layer1.0.bn3.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.808 algo-1:73 INFO hook.py:560] name:layer1.0.se_module.fc1.weight count_params:4096\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.808 algo-1:73 INFO hook.py:560] name:layer1.0.se_module.fc1.bias count_params:16\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.808 algo-1:73 INFO hook.py:560] name:layer1.0.se_module.fc2.weight count_params:4096\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.809 algo-1:73 INFO hook.py:560] name:layer1.0.se_module.fc2.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.809 algo-1:73 INFO hook.py:560] name:layer1.0.downsample.0.weight count_params:16384\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.809 algo-1:73 INFO hook.py:560] name:layer1.0.downsample.1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.809 algo-1:73 INFO hook.py:560] name:layer1.0.downsample.1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.809 algo-1:73 INFO hook.py:560] name:layer1.1.conv1.weight count_params:32768\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.809 algo-1:73 INFO hook.py:560] name:layer1.1.bn1.weight count_params:128\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.810 algo-1:73 INFO hook.py:560] name:layer1.1.bn1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.810 algo-1:73 INFO hook.py:560] name:layer1.1.conv2.weight count_params:4608\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.810 algo-1:73 INFO hook.py:560] name:layer1.1.bn2.weight count_params:128\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.810 algo-1:73 INFO hook.py:560] name:layer1.1.bn2.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.810 algo-1:73 INFO hook.py:560] name:layer1.1.conv3.weight count_params:32768\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.810 algo-1:73 INFO hook.py:560] name:layer1.1.bn3.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.810 algo-1:73 INFO hook.py:560] name:layer1.1.bn3.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.811 algo-1:73 INFO hook.py:560] name:layer1.1.se_module.fc1.weight count_params:4096\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.811 algo-1:73 INFO hook.py:560] name:layer1.1.se_module.fc1.bias count_params:16\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.811 algo-1:73 INFO hook.py:560] name:layer1.1.se_module.fc2.weight count_params:4096\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.811 algo-1:73 INFO hook.py:560] name:layer1.1.se_module.fc2.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.811 algo-1:73 INFO hook.py:560] name:layer2.0.conv1.weight count_params:65536\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.811 algo-1:73 INFO hook.py:560] name:layer2.0.bn1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.812 algo-1:73 INFO hook.py:560] name:layer2.0.bn1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.812 algo-1:73 INFO hook.py:560] name:layer2.0.conv2.weight count_params:18432\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.812 algo-1:73 INFO hook.py:560] name:layer2.0.bn2.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.812 algo-1:73 INFO hook.py:560] name:layer2.0.bn2.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.812 algo-1:73 INFO hook.py:560] name:layer2.0.conv3.weight count_params:131072\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.812 algo-1:73 INFO hook.py:560] name:layer2.0.bn3.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.812 algo-1:73 INFO hook.py:560] name:layer2.0.bn3.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.813 algo-1:73 INFO hook.py:560] name:layer2.0.se_module.fc1.weight count_params:16384\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.813 algo-1:73 INFO hook.py:560] name:layer2.0.se_module.fc1.bias count_params:32\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.813 algo-1:73 INFO hook.py:560] name:layer2.0.se_module.fc2.weight count_params:16384\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.813 algo-1:73 INFO hook.py:560] name:layer2.0.se_module.fc2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.813 algo-1:73 INFO hook.py:560] name:layer2.0.downsample.0.weight count_params:131072\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.813 algo-1:73 INFO hook.py:560] name:layer2.0.downsample.1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.813 algo-1:73 INFO hook.py:560] name:layer2.0.downsample.1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.814 algo-1:73 INFO hook.py:560] name:layer2.1.conv1.weight count_params:131072\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.814 algo-1:73 INFO hook.py:560] name:layer2.1.bn1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.814 algo-1:73 INFO hook.py:560] name:layer2.1.bn1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.814 algo-1:73 INFO hook.py:560] name:layer2.1.conv2.weight count_params:18432\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.814 algo-1:73 INFO hook.py:560] name:layer2.1.bn2.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.814 algo-1:73 INFO hook.py:560] name:layer2.1.bn2.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.814 algo-1:73 INFO hook.py:560] name:layer2.1.conv3.weight count_params:131072\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.815 algo-1:73 INFO hook.py:560] name:layer2.1.bn3.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.815 algo-1:73 INFO hook.py:560] name:layer2.1.bn3.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.815 algo-1:73 INFO hook.py:560] name:layer2.1.se_module.fc1.weight count_params:16384\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.815 algo-1:73 INFO hook.py:560] name:layer2.1.se_module.fc1.bias count_params:32\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.815 algo-1:73 INFO hook.py:560] name:layer2.1.se_module.fc2.weight count_params:16384\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.815 algo-1:73 INFO hook.py:560] name:layer2.1.se_module.fc2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.815 algo-1:73 INFO hook.py:560] name:layer3.0.conv1.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.816 algo-1:73 INFO hook.py:560] name:layer3.0.bn1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.816 algo-1:73 INFO hook.py:560] name:layer3.0.bn1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.816 algo-1:73 INFO hook.py:560] name:layer3.0.conv2.weight count_params:73728\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.816 algo-1:73 INFO hook.py:560] name:layer3.0.bn2.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.816 algo-1:73 INFO hook.py:560] name:layer3.0.bn2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.816 algo-1:73 INFO hook.py:560] name:layer3.0.conv3.weight count_params:524288\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.816 algo-1:73 INFO hook.py:560] name:layer3.0.bn3.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.817 algo-1:73 INFO hook.py:560] name:layer3.0.bn3.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.817 algo-1:73 INFO hook.py:560] name:layer3.0.se_module.fc1.weight count_params:65536\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.817 algo-1:73 INFO hook.py:560] name:layer3.0.se_module.fc1.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.817 algo-1:73 INFO hook.py:560] name:layer3.0.se_module.fc2.weight count_params:65536\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.817 algo-1:73 INFO hook.py:560] name:layer3.0.se_module.fc2.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.817 algo-1:73 INFO hook.py:560] name:layer3.0.downsample.0.weight count_params:524288\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.818 algo-1:73 INFO hook.py:560] name:layer3.0.downsample.1.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.818 algo-1:73 INFO hook.py:560] name:layer3.0.downsample.1.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.818 algo-1:73 INFO hook.py:560] name:layer3.1.conv1.weight count_params:524288\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.818 algo-1:73 INFO hook.py:560] name:layer3.1.bn1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.818 algo-1:73 INFO hook.py:560] name:layer3.1.bn1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.818 algo-1:73 INFO hook.py:560] name:layer3.1.conv2.weight count_params:73728\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.818 algo-1:73 INFO hook.py:560] name:layer3.1.bn2.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.819 algo-1:73 INFO hook.py:560] name:layer3.1.bn2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.819 algo-1:73 INFO hook.py:560] name:layer3.1.conv3.weight count_params:524288\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.819 algo-1:73 INFO hook.py:560] name:layer3.1.bn3.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.819 algo-1:73 INFO hook.py:560] name:layer3.1.bn3.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.819 algo-1:73 INFO hook.py:560] name:layer3.1.se_module.fc1.weight count_params:65536\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.819 algo-1:73 INFO hook.py:560] name:layer3.1.se_module.fc1.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.819 algo-1:73 INFO hook.py:560] name:layer3.1.se_module.fc2.weight count_params:65536\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.820 algo-1:73 INFO hook.py:560] name:layer3.1.se_module.fc2.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.820 algo-1:73 INFO hook.py:560] name:layer4.0.conv1.weight count_params:1048576\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.820 algo-1:73 INFO hook.py:560] name:layer4.0.bn1.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.820 algo-1:73 INFO hook.py:560] name:layer4.0.bn1.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.820 algo-1:73 INFO hook.py:560] name:layer4.0.conv2.weight count_params:294912\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.820 algo-1:73 INFO hook.py:560] name:layer4.0.bn2.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.820 algo-1:73 INFO hook.py:560] name:layer4.0.bn2.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.821 algo-1:73 INFO hook.py:560] name:layer4.0.conv3.weight count_params:2097152\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.821 algo-1:73 INFO hook.py:560] name:layer4.0.bn3.weight count_params:2048\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.821 algo-1:73 INFO hook.py:560] name:layer4.0.bn3.bias count_params:2048\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.821 algo-1:73 INFO hook.py:560] name:layer4.0.se_module.fc1.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.821 algo-1:73 INFO hook.py:560] name:layer4.0.se_module.fc1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.821 algo-1:73 INFO hook.py:560] name:layer4.0.se_module.fc2.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.822 algo-1:73 INFO hook.py:560] name:layer4.0.se_module.fc2.bias count_params:2048\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.822 algo-1:73 INFO hook.py:560] name:layer4.0.downsample.0.weight count_params:2097152\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.822 algo-1:73 INFO hook.py:560] name:layer4.0.downsample.1.weight count_params:2048\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.822 algo-1:73 INFO hook.py:560] name:layer4.0.downsample.1.bias count_params:2048\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.822 algo-1:73 INFO hook.py:560] name:layer4.1.conv1.weight count_params:2097152\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.822 algo-1:73 INFO hook.py:560] name:layer4.1.bn1.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.822 algo-1:73 INFO hook.py:560] name:layer4.1.bn1.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.822 algo-1:73 INFO hook.py:560] name:layer4.1.conv2.weight count_params:294912\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.823 algo-1:73 INFO hook.py:560] name:layer4.1.bn2.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.823 algo-1:73 INFO hook.py:560] name:layer4.1.bn2.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.823 algo-1:73 INFO hook.py:560] name:layer4.1.conv3.weight count_params:2097152\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.823 algo-1:73 INFO hook.py:560] name:layer4.1.bn3.weight count_params:2048\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.823 algo-1:73 INFO hook.py:560] name:layer4.1.bn3.bias count_params:2048\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.823 algo-1:73 INFO hook.py:560] name:layer4.1.se_module.fc1.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.824 algo-1:73 INFO hook.py:560] name:layer4.1.se_module.fc1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.824 algo-1:73 INFO hook.py:560] name:layer4.1.se_module.fc2.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.824 algo-1:73 INFO hook.py:560] name:layer4.1.se_module.fc2.bias count_params:2048\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.824 algo-1:73 INFO hook.py:562] Total Trainable Params: 14741280\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.824 algo-1:73 INFO hook.py:421] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.824 algo-1:73 INFO state_store.py:115] Timestamps of different checkpoint files [('/opt/ml/checkpoints/no_windows/train_opt.txt', 1661521421.6218147)]\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:43:55.825 algo-1:73 INFO hook.py:485] Hook is writing from the hook with pid: 73\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:780: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.\n",
      "  warnings.warn(\"Note that order of the arguments: ceil_mode and return_indices will change\"\u001b[0m\n",
      "\u001b[34m[torch.Size([1, 64, 128, 128]), torch.Size([1, 256, 64, 64]), torch.Size([1, 512, 32, 32]), torch.Size([1, 1024, 16, 16]), torch.Size([1, 2048, 8, 8])]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[2022-08-26 13:44:00.320 algo-1:73 INFO state_store.py:115] Timestamps of different checkpoint files [('/opt/ml/checkpoints/no_windows/train_opt.txt', 1661521421.6218147)]\u001b[0m\n",
      "\u001b[34mINFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 0\u001b[0m\n",
      "\u001b[34mINFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.\u001b[0m\n",
      "\u001b[34malgo-1:73:73 [0] ofi_init:1304 NCCL WARN NET/OFI Only EFA provider is supported\u001b[0m\n",
      "\u001b[34malgo-1:73:73 [0] ofi_init:1355 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34mNCCL version 2.10.3+cuda11.3\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:489: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\u001b[0m\n",
      "\u001b[34m[!] [Errno 2] No such file or directory: '/opt/ml/checkpoints/no_windows/latest_netG.pth', skipping weights loading.\u001b[0m\n",
      "\u001b[34mEpoch  1:   0%|          | 0/7696 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[2022-08-26 13:44:03.410 algo-1:73 INFO state_store.py:115] Timestamps of different checkpoint files [('/opt/ml/checkpoints/no_windows/train_opt.txt', 1661521421.6218147)]\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2228.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\u001b[0m\n",
      "\u001b[34mEpoch  1:   0%|          | 0/7696 [00:18<?, ?it/s, lossG=6.72, lossD=0.813, nce_loss_tot=5.22]\u001b[0m\n",
      "\u001b[34mEpoch  1:   0%|          | 1/7696 [00:18<40:19:58, 18.87s/it, lossG=6.72, lossD=0.813, nce_loss_tot=5.22]\u001b[0m\n",
      "\u001b[34mEpoch  1:   0%|          | 2/7696 [00:19<18:01:10,  8.43s/it, lossG=6.72, lossD=0.813, nce_loss_tot=5.22]\u001b[0m\n",
      "\u001b[34mEpoch  1:   0%|          | 3/7696 [00:21<11:03:17,  5.17s/it, lossG=6.72, lossD=0.813, nce_loss_tot=5.22]\u001b[0m\n",
      "\u001b[34mEpoch  1:   0%|          | 4/7696 [00:22<7:37:17,  3.57s/it, lossG=6.72, lossD=0.813, nce_loss_tot=5.22]\u001b[0m\n",
      "\u001b[34mEpoch  1:   0%|          | 5/7696 [00:23<5:42:26,  2.67s/it, lossG=6.72, lossD=0.813, nce_loss_tot=5.22]\u001b[0m\n",
      "\u001b[34mEpoch  1:   0%|          | 6/7696 [00:24<4:33:11,  2.13s/it, lossG=6.72, lossD=0.813, nce_loss_tot=5.22]\u001b[0m\n",
      "\u001b[34mEpoch  1:   0%|          | 7/7696 [00:25<3:52:23,  1.81s/it, lossG=6.72, lossD=0.813, nce_loss_tot=5.22]\u001b[0m\n",
      "\u001b[34mEpoch  1:   0%|          | 8/7696 [00:27<3:51:58,  1.81s/it, lossG=6.72, lossD=0.813, nce_loss_tot=5.22]\u001b[0m\n",
      "\u001b[34mEpoch  1:   0%|          | 9/7696 [00:28<3:26:43,  1.61s/it, lossG=6.72, lossD=0.813, nce_loss_tot=5.22]\u001b[0m\n",
      "\u001b[34mEpoch  1:   0%|          | 10/7696 [00:29<3:10:07,  1.48s/it, lossG=6.72, lossD=0.813, nce_loss_tot=5.22]\u001b[0m\n",
      "\u001b[34mEpoch  1:   0%|          | 11/7696 [00:31<2:57:29,  1.39s/it, lossG=6.72, lossD=0.813, nce_loss_tot=5.22]\u001b[0m\n",
      "\u001b[34mEpoch  1:   0%|          | 12/7696 [00:32<2:48:50,  1.32s/it, lossG=6.72, lossD=0.813, nce_loss_tot=5.22]\u001b[0m\n",
      "\u001b[34mEpoch  1:   0%|          | 13/7696 [00:33<2:42:56,  1.27s/it, lossG=6.72, lossD=0.813, nce_loss_tot=5.22]\u001b[0m\n",
      "\u001b[34mEpoch  1:   0%|          | 14/7696 [00:34<2:38:40,  1.24s/it, lossG=6.72, lossD=0.813, nce_loss_tot=5.22]\u001b[0m\n",
      "\u001b[34mEpoch  1:   0%|          | 15/7696 [00:35<2:35:44,  1.22s/it, lossG=6.72, lossD=0.813, nce_loss_tot=5.22]\u001b[0m\n",
      "\u001b[34mEpoch  1:   0%|          | 16/7696 [00:36<2:33:44,  1.20s/it, lossG=6.72, lossD=0.813, nce_loss_tot=5.22]\u001b[0m\n",
      "\u001b[34mEpoch  1:   0%|          | 17/7696 [00:38<2:32:13,  1.19s/it, lossG=6.72, lossD=0.813, nce_loss_tot=5.22]\u001b[0m\n",
      "\u001b[34mEpoch  1:   0%|          | 18/7696 [00:39<2:31:18,  1.18s/it, lossG=6.72, lossD=0.813, nce_loss_tot=5.22]\u001b[0m\n",
      "\u001b[34mEpoch  1:   0%|          | 19/7696 [00:40<2:30:33,  1.18s/it, lossG=6.72, lossD=0.813, nce_loss_tot=5.22]\u001b[0m\n",
      "\u001b[34mEpoch  1:   0%|          | 20/7696 [00:41<2:30:10,  1.17s/it, lossG=6.72, lossD=0.813, nce_loss_tot=5.22]\u001b[0m\n",
      "\u001b[34mEpoch  1:   0%|          | 20/7696 [00:42<2:30:10,  1.17s/it, lossG=4.55, lossD=0.887, nce_loss_tot=3.6]\u001b[0m\n",
      "\u001b[34mEpoch  1:   0%|          | 21/7696 [00:42<2:29:47,  1.17s/it, lossG=4.55, lossD=0.887, nce_loss_tot=3.6]\u001b[0m\n",
      "\u001b[34mEpoch  1:   0%|          | 22/7696 [00:43<2:29:30,  1.17s/it, lossG=4.55, lossD=0.887, nce_loss_tot=3.6]\u001b[0m\n",
      "\u001b[34mEpoch  1:   0%|          | 23/7696 [00:45<2:29:20,  1.17s/it, lossG=4.55, lossD=0.887, nce_loss_tot=3.6]\u001b[0m\n",
      "\u001b[34mEpoch  1:   0%|          | 24/7696 [00:46<2:29:06,  1.17s/it, lossG=4.55, lossD=0.887, nce_loss_tot=3.6]\u001b[0m\n",
      "\u001b[34mEpoch  1:   0%|          | 25/7696 [00:47<2:28:50,  1.16s/it, lossG=4.55, lossD=0.887, nce_loss_tot=3.6]\u001b[0m\n",
      "\u001b[34mEpoch  1:   0%|          | 26/7696 [00:48<2:28:46,  1.16s/it, lossG=4.55, lossD=0.887, nce_loss_tot=3.6]\u001b[0m\n",
      "\u001b[34mEpoch  1:   0%|          | 27/7696 [00:49<2:28:48,  1.16s/it, lossG=4.55, lossD=0.887, nce_loss_tot=3.6]\u001b[0m\n",
      "\u001b[34mEpoch  1:   0%|          | 28/7696 [00:50<2:28:40,  1.16s/it, lossG=4.55, lossD=0.887, nce_loss_tot=3.6]\u001b[0m\n",
      "\u001b[34mEpoch  1:   0%|          | 29/7696 [00:52<2:29:05,  1.17s/it, lossG=4.55, lossD=0.887, nce_loss_tot=3.6]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({'train': 's3://ai-sagemaker-datasets/seat_gen_unpaired/'}, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408781b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d2152fd7f0bbc62aa1baff8c990435d1e2c7175d001561303988032604c11a48"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
